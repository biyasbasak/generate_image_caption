{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
        }
      }
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAxOdskQhtEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba24b531-4a38-4c50-9a4f-99ae7d680074"
      },
      "source": [
        "!pip install nltk\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmbSqacWe4sS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70622edf-4d16-43f2-981c-405d29a39b0e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X06HSXqYe4sS"
      },
      "source": [
        "df = pd.read_csv(\"captions.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVfDC-nYe4sS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1bc105-e988-4f3b-fc8f-ed2c5cf486e1"
      },
      "source": [
        "images = df.iloc[:, 0]\n",
        "captions = df.iloc[:, 1]\n",
        "print(images.shape)\n",
        "print(captions.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40455,)\n",
            "(40455,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZdOU3Ude4sT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a82b437-8491-4507-97a9-993b277b59cf"
      },
      "source": [
        "#### preprocess the captions #######\n",
        "for i, caption in enumerate(captions):\n",
        "    _caption = caption.lower()\n",
        "    tokens = _caption.split()\n",
        "    tokens = [word for word in tokens if not word in stop_words]\n",
        "    # token length greater than one. removes dangling characters\n",
        "    tokens = [word for word in tokens if len(word)>1]\n",
        "    # remove tokens with numbers in them\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    captions[i] = \" \".join(tokens)\n",
        "\n",
        "\n",
        "print(captions[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    child pink dress climbing set stairs entry way\n",
            "1                        girl going wooden building\n",
            "2             little girl climbing wooden playhouse\n",
            "3             little girl climbing stairs playhouse\n",
            "4         little girl pink dress going wooden cabin\n",
            "Name: caption, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgHIzcKxjFp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f531294a-25ba-4e63-a7a4-2846e5911224"
      },
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(images, captions)\n",
        "print(train_x[0:5])\n",
        "print(train_y[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19590    3074842262_62b1b2168c.jpg\n",
            "7529     2310108346_e82d209ccd.jpg\n",
            "5269     2121357310_f8235311da.jpg\n",
            "29123    3474265683_43b1033d94.jpg\n",
            "331      1084104085_3b06223afe.jpg\n",
            "Name: image, dtype: object\n",
            "19590                                boy kicks pile leaves\n",
            "7529                person sweater sits wood looking water\n",
            "5269                       boy sliding wet plastic surface\n",
            "29123    old wearing grey hat leather jacket surrounded...\n",
            "331      woman blue shorts white shirt indoor rock clim...\n",
            "Name: caption, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "0Ql7JmQDe4sT"
      },
      "source": [
        "#### Create a vocabulary from the train captions in train_y #####\n",
        "\n",
        "vocabulary = set()\n",
        "\n",
        "for caption in train_y:\n",
        "    tokens = caption.split(\" \")\n",
        "    for token in tokens:\n",
        "        vocabulary.add(token)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "rKNuD8KFe4sT"
      },
      "source": [
        "#### create a list of captions corresponding to a particular image ######\n",
        "\n",
        "image_to_caption = defaultdict(list)\n",
        "\n",
        "for image, caption in zip(images, captions):\n",
        "    _image = image.replace(\".jpg\", \"\").strip()\n",
        "    image_to_caption[_image].append(caption)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQQsxPE7e4sT"
      },
      "source": [
        "model = InceptionV3(weights=\"imagenet\")\n",
        "model = Model(model.input, model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTA7dIX5nbXh"
      },
      "source": [
        "# Convert all the images to size 299x299 as expected by the\n",
        "# encoded_images = []\n",
        "# for image in images:\n",
        "#   path = path.join(\"images\", image)\n",
        "#   img = image.load_img(path, target_size=(299, 299))\n",
        "#   X = image.img_to_array(img)\n",
        "#   X = np.expand_dims(x, axis=0)\n",
        "#   X = preprocess_input(x)\n",
        "#   X = np.reshape(x, x.shape[1])\n",
        "\n",
        "\n",
        "image_path = path.join(\"images\",\"1000268201_693b08cb0e.jpg\")\n",
        "img = image.load_img(image_path, target_size=(299, 299))\n",
        "X = image.img_to_array(img)\n",
        "X = np.expand_dims(X, axis=0)\n",
        "X = preprocess_input(X)\n",
        "\n",
        "X.shape\n",
        "# X = np.reshape(X, X.shape[1])\n",
        "\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}